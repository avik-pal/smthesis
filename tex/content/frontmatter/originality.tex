\chapter*{Originality}

The writing of this thesis is my original work. The material in this thesis is either my original work with or without collaborators, or is based on the work of others duly cited.

\section*{Publications}

This thesis contains materials from the following publications/pre-prints listed in chronological order:

\textbf{Opening the Blackbox: Accelerating Neural Differential Equations by Regularizing Internal Solver Heuristics}\\
Avik Pal, Yingbo Ma, Viral Shah, Chris Rackauckas\\
\textit{International Conference on Machine Learning (ICML)}, 2021.

\textbf{Continuous Deep Equilibrium Models: Training Neural ODEs Faster by Integrating Them to Infinity}\\
Avik Pal, Alan Edelman, Chris Rackauckas\\
\textit{arXiv preprint arXiv:2201.12240}, 2022.

\textbf{Locally Regularized Neural Differential Equations: Some Black Boxes Were Meant to Remain Closed!}\\
Avik Pal, Alan Edelman, Chris Rackauckas\\
\textit{International Conference on Machine Learning (ICML)}, 2023.

\section*{Open Source Software}

A substantial part of my Masters was dedicated to writing and contributing open source software. I believe these software have enabled other researchers and practitioners to build upon my work and help accelerate the pace of research in the field of scientific machine learning. The following are the open source software that I have written:

\textbf{Lux.jl}: Explicitly Parameterized Neural Networks in Julia\\
{\small \url{https://github.com/LuxDL/Lux.jl}}

\textbf{DeepEquilibriumNetworks.jl}: Fast Discrete and Continuous Deep Equilibrium Networks\\
{\small \url{https://github.com/SciML/DeepEquilibriumNetworks.jl}}

\section*{Breakdown of Contributions}

\citet{pal2022mixing} and \citet{pal2023locally} were written and published during my Masters at MIT. \citet{pal2021opening} was published prior to me joining MIT and it has been included in my thesis to provide a coherent story about acceleration of Neural Differential Equations, since a detailed discussion on \citet{pal2023locally} is not possible without the preceding version of the paper~\citep{pal2021opening}.

All the software mentioned above were written during my Masters at MIT. \textit{Lux.jl} development was heavily inspired by my prior experience in developing \textit{Flux.jl}~\citep{innes:2018, innes2018fashionable}. \textit{DeepEquilibriumNetworks.jl} was written as a part of my research on \citet{pal2022mixing}. 
