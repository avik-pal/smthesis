@misc{rackauckas2019scimlbook,
  author       = {Rackauckas, Chris},
  title        = {Parallel Computing and Scientific Machine Learning (SciML): Methods and Applications (MIT 18.337J/6.338J)},
  year         = {2019},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/SciML/SciMLBook}}
}

@article{kim2021stiff,
  title     = {Stiff neural ordinary differential equations},
  author    = {Kim, Suyong and Ji, Weiqi and Deng, Sili and Ma, Yingbo and Rackauckas, Christopher},
  journal   = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume    = {31},
  number    = {9},
  pages     = {093122},
  year      = {2021},
  publisher = {AIP Publishing LLC}
}

@book{wanner1996solving,
  title     = {Solving ordinary differential equations II},
  author    = {Wanner, Gerhard and Hairer, Ernst},
  volume    = {375},
  year      = {1996},
  publisher = {Springer Berlin Heidelberg New York}
}

@book{euler1824institutionum,
  title     = {Institutionum calculi integralis},
  author    = {Euler, Leonhard},
  volume    = {1},
  year      = {1824},
  publisher = {impensis Academiae imperialis scientiarum}
}

@article{tsitouras2011runge,
  title     = {Runge--Kutta pairs of order 5 (4) satisfying only the first column simplifying assumption},
  author    = {Tsitouras, Ch},
  journal   = {Computers \& Mathematics with Applications},
  volume    = {62},
  number    = {2},
  pages     = {770--775},
  year      = {2011},
  publisher = {Elsevier}
}

@article{durran1991third,
  title   = {The third-order Adams-Bashforth method: An attractive alternative to leapfrog time differencing},
  author  = {Durran, Dale R},
  journal = {Monthly weather review},
  volume  = {119},
  number  = {3},
  pages   = {702--720},
  year    = {1991}
}

@article{kelly2020learning,
  title   = {Learning differential equations that are easy to solve},
  author  = {Kelly, Jacob and Bettencourt, Jesse and Johnson, Matthew James and Duvenaud, David},
  journal = {arXiv preprint arXiv:2007.04504},
  year    = {2020}
}

@inproceedings{chen2018neural,
  title     = {Neural ordinary differential equations},
  author    = {Chen, Ricky TQ and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  booktitle = {Advances in neural information processing systems},
  pages     = {6571--6583},
  year      = {2018}
}

@article{finlay2020train,
  title   = {How to train your neural ode},
  author  = {Finlay, Chris and Jacobsen, J{\"o}rn-Henrik and Nurbekyan, Levon and Oberman, Adam M},
  journal = {arXiv preprint arXiv:2002.02798},
  year    = {2020}
}

@article{grathwohl2018ffjord,
  title   = {Ffjord: Free-form continuous dynamics for scalable reversible generative models},
  author  = {Grathwohl, Will and Chen, Ricky TQ and Bettencourt, Jesse and Sutskever, Ilya and Duvenaud, David},
  journal = {arXiv preprint arXiv:1810.01367},
  year    = {2018}
}

@article{rubanova2019latent,
  title   = {Latent odes for irregularly-sampled time series},
  author  = {Rubanova, Yulia and Chen, Ricky TQ and Duvenaud, David},
  journal = {arXiv preprint arXiv:1907.03907},
  year    = {2019}
}

@article{rackauckas2019diffeqflux,
  author        = {Christopher Rackauckas and
                   Mike Innes and
                   Yingbo Ma and
                   Jesse Bettencourt and
                   Lyndon White and
                   Vaibhav Dixit},
  title         = {DiffEqFlux.jl - {A} Julia Library for Neural Differential Equations},
  journal       = {CoRR},
  volume        = {abs/1902.02376},
  year          = {2019},
  url           = {http://arxiv.org/abs/1902.02376},
  archiveprefix = {arXiv},
  eprint        = {1902.02376},
  timestamp     = {Tue, 21 May 2019 18:03:36 +0200},
  biburl        = {https://dblp.org/rec/bib/journals/corr/abs-1902-02376},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{innes2018fashionable,
  author        = {Michael Innes and
                   Elliot Saba and
                   Keno Fischer and
                   Dhairya Gandhi and
                   Marco Concetto Rudilosso and
                   Neethu Mariya Joy and
                   Tejan Karmali and
                   Avik Pal and
                   Viral Shah},
  title         = {Fashionable Modelling with Flux},
  journal       = {CoRR},
  volume        = {abs/1811.01457},
  year          = {2018},
  url           = {http://arxiv.org/abs/1811.01457},
  archiveprefix = {arXiv},
  eprint        = {1811.01457},
  timestamp     = {Thu, 22 Nov 2018 17:58:30 +0100},
  biburl        = {https://dblp.org/rec/bib/journals/corr/abs-1811-01457},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{silva2012predicting,
  title        = {Predicting in-hospital mortality of icu patients: The physionet/computing in cardiology challenge 2012},
  author       = {Silva, Ikaro and Moody, George and Scott, Daniel J and Celi, Leo A and Mark, Roger G},
  booktitle    = {2012 Computing in Cardiology},
  pages        = {245--248},
  year         = {2012},
  organization = {IEEE}
}

@article{qian1999momentum,
  title     = {On the momentum term in gradient descent learning algorithms},
  author    = {Qian, Ning},
  journal   = {Neural networks},
  volume    = {12},
  number    = {1},
  pages     = {145--151},
  year      = {1999},
  publisher = {Elsevier}
}


@article{kutta1901beitrag,
  title   = {Beitrag zur naherungsweisen Integration totaler Differentialgleichungen},
  author  = {Kutta, Wilhelm},
  journal = {Z. Math. Phys.},
  volume  = {46},
  pages   = {435--453},
  year    = {1901}
}

@article{runge1895numerische,
  title     = {{\"U}ber die numerische Aufl{\"o}sung von Differentialgleichungen},
  author    = {Runge, Carl},
  journal   = {Mathematische Annalen},
  volume    = {46},
  number    = {2},
  pages     = {167--178},
  year      = {1895},
  publisher = {Springer}
}

@book{fehlberg1968classical,
  title     = {Classical fifth-, sixth-, seventh-, and eighth-order Runge-Kutta formulas with stepsize control},
  author    = {Fehlberg, Erwin},
  year      = {1968},
  publisher = {National Aeronautics and Space Administration}
}

@book{ascher1998computer,
  title     = {Computer methods for ordinary differential equations and differential-algebraic equations},
  author    = {Ascher, Uri M and Petzold, Linda R},
  volume    = {61},
  year      = {1998},
  publisher = {Siam}
}

@misc{liu2019neural,
  title         = {Neural SDE: Stabilizing Neural ODE Networks with Stochastic Noise},
  author        = {Xuanqing Liu and Tesi Xiao and Si Si and Qin Cao and Sanjiv Kumar and Cho-Jui Hsieh},
  year          = {2019},
  eprint        = {1906.02355},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{rackauckas2020universal,
  title         = {Universal Differential Equations for Scientific Machine Learning},
  author        = {Christopher Rackauckas and Yingbo Ma and Julius Martensen and Collin Warner and Kirill Zubov and Rohit Supekar and Dominic Skinner and Ali Ramadhan and Alan Edelman},
  year          = {2020},
  eprint        = {2001.04385},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{Julia-2017,
  title     = {Julia: A fresh approach to numerical computing},
  author    = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B},
  journal   = {SIAM {R}eview},
  volume    = {59},
  number    = {1},
  pages     = {65--98},
  year      = {2017},
  publisher = {SIAM},
  doi       = {10.1137/141000671}
}

@inproceedings{lu2018beyond,
  title        = {Beyond finite layer neural networks: Bridging deep architectures and numerical differential equations},
  author       = {Lu, Yiping and Zhong, Aoxiao and Li, Quanzheng and Dong, Bin},
  booktitle    = {International Conference on Machine Learning},
  pages        = {3276--3285},
  year         = {2018},
  organization = {PMLR}
}

@misc{he2015deep,
  title         = {Deep Residual Learning for Image Recognition},
  author        = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  year          = {2015},
  eprint        = {1512.03385},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@book{hairer1,
  author = {Hairer, Ernst and Norsett, Syvert and Wanner, G.},
  year   = {1993},
  month  = {01},
  pages  = {},
  title  = {Solving Ordinary Differential Equations I: Nonstiff Problems},
  volume = {8},
  isbn   = {978-3-540-56670-0},
  doi    = {10.1007/978-3-540-78862-1}
}

@article{shampine1977stiffness,
  author     = {Shampine, L. F.},
  title      = {Stiffness and Nonstiff Differential Equation Solvers, II: Detecting Stiffness with Runge-Kutta Methods},
  year       = {1977},
  issue_date = {March 1977},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {3},
  number     = {1},
  issn       = {0098-3500},
  url        = {https://doi.org/10.1145/355719.355722},
  doi        = {10.1145/355719.355722},
  journal    = {ACM Trans. Math. Softw.},
  month      = mar,
  pages      = {44–53},
  numpages   = {10}
}

@inproceedings{rackauckas2020sosri,
  title        = {Stability-optimized high order methods and stiffness detection for pathwise stiff stochastic differential equations},
  author       = {Rackauckas, Chris and Nie, Qing},
  booktitle    = {2020 IEEE High Performance Extreme Computing Conference (HPEC)},
  pages        = {1--8},
  year         = {2020},
  organization = {IEEE}
}

@article{hutchinson1989stochastic,
  title     = {A stochastic estimator of the trace of the influence matrix for Laplacian smoothing splines},
  author    = {Hutchinson, Michael F},
  journal   = {Communications in Statistics-Simulation and Computation},
  volume    = {18},
  number    = {3},
  pages     = {1059--1076},
  year      = {1989},
  publisher = {Taylor \& Francis}
}

@article{dormand1980family,
  title     = {A family of embedded Runge-Kutta formulae},
  author    = {Dormand, John R and Prince, Peter J},
  journal   = {Journal of computational and applied mathematics},
  volume    = {6},
  number    = {1},
  pages     = {19--26},
  year      = {1980},
  publisher = {Elsevier}
}

@article{shampine1979user,
  title     = {A user’s view of solving stiff ordinary differential equations},
  author    = {Shampine, Lawrence F and Gear, Charles William},
  journal   = {SIAM review},
  volume    = {21},
  number    = {1},
  pages     = {1--17},
  year      = {1979},
  publisher = {SIAM}
}

@article{shampine2007stiff,
  title   = {Stiff systems},
  author  = {Shampine, Lawrence F and Thompson, Skip},
  journal = {Scholarpedia},
  volume  = {2},
  number  = {3},
  pages   = {2855},
  year    = {2007}
}

@article{higham1993stiffness,
  title     = {Stiffness of odes},
  author    = {Higham, Desmond J and Trefethen, Lloyd N},
  journal   = {BIT Numerical Mathematics},
  volume    = {33},
  number    = {2},
  pages     = {285--303},
  year      = {1993},
  publisher = {Springer}
}

@article{rackauckas2019confederated,
  title     = {Confederated modular differential equation APIs for accelerated algorithm development and benchmarking},
  author    = {Rackauckas, Christopher and Nie, Qing},
  journal   = {Advances in Engineering Software},
  volume    = {132},
  pages     = {1--6},
  year      = {2019},
  publisher = {Elsevier}
}

@article{zhuang2020adabelief,
  title   = {AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients},
  author  = {Zhuang, Juntang and Tang, Tommy and Ding, Yifan and Tatikonda, Sekhar and Dvornek, Nicha and Papademetris, Xenophon and Duncan, James},
  journal = {Conference on Neural Information Processing Systems},
  year    = {2020}
}

@article{rackauckas2017adaptive,
  title     = {Adaptive methods for stochastic differential equations via natural embeddings and rejection sampling with memory},
  author    = {Rackauckas, Christopher and Nie, Qing},
  journal   = {Discrete and continuous dynamical systems. Series B},
  volume    = {22},
  number    = {7},
  pages     = {2731},
  year      = {2017},
  publisher = {NIH Public Access}
}

@article{gholami2019anode,
  title   = {Anode: Unconditionally accurate memory-efficient gradients for neural odes},
  author  = {Gholami, Amir and Keutzer, Kurt and Biros, George},
  journal = {arXiv preprint arXiv:1902.10298},
  year    = {2019}
}

@article{zhang2014fatode,
  title     = {FATODE: a library for forward, adjoint, and tangent linear integration of ODEs},
  author    = {Zhang, Hong and Sandu, Adrian},
  journal   = {SIAM Journal on Scientific Computing},
  volume    = {36},
  number    = {5},
  pages     = {C504--C523},
  year      = {2014},
  publisher = {SIAM}
}

@article{onken2020discretize,
  title   = {Discretize-optimize vs. optimize-discretize for time-series regression and continuous normalizing flows},
  author  = {Onken, Derek and Ruthotto, Lars},
  journal = {arXiv preprint arXiv:2005.13420},
  year    = {2020}
}

@inproceedings{dauvergne2006data,
  title        = {The data-flow equations of checkpointing in reverse automatic differentiation},
  author       = {Dauvergne, Benjamin and Hasco{\"e}t, Laurent},
  booktitle    = {International Conference on Computational Science},
  pages        = {566--573},
  year         = {2006},
  organization = {Springer}
}

@misc{revels2017reversediff,
  title  = {Reversediff},
  author = {Revels, Jarrett},
  year   = {2017}
}

@article{innes2018don,
  title   = {Don't unroll adjoint: Differentiating ssa-form programs},
  author  = {Innes, Michael},
  journal = {arXiv preprint arXiv:1810.07951},
  year    = {2018}
}

@inproceedings{zhang2008computing,
  title        = {Computing the High Order Derivatives with Automatic Differentiation and Its Application in Chebyshev's Method},
  author       = {Zhang, Haibin and Xue, Yi and Zhang, Chunhua and Dong, Lili},
  booktitle    = {2008 Fourth International Conference on Natural Computation},
  volume       = {1},
  pages        = {304--308},
  year         = {2008},
  organization = {IEEE}
}

@inproceedings{rackauckas2020generalized,
  title  = {Generalized Physics-Informed Learning through Language-Wide Differentiable Programming.},
  author = {Rackauckas, Christopher and Edelman, Alan and Fischer, Keno and Innes, Mike and Saba, Elliot and Shah, Viral B and Tebbutt, Will}
}

@article{abadi2019simple,
  title     = {A simple differentiable programming language},
  author    = {Abadi, Mart{\'\i}n and Plotkin, Gordon D},
  journal   = {Proceedings of the ACM on Programming Languages},
  volume    = {4},
  number    = {POPL},
  pages     = {1--28},
  year      = {2019},
  publisher = {ACM New York, NY, USA}
}

@article{wang2018backpropagation,
  title   = {Backpropagation with callbacks: Foundations for efficient and expressive differentiable programming},
  author  = {Wang, Fei and Decker, James and Wu, Xilun and Essertel, Gregory and Rompf, Tiark},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {31},
  pages   = {10180--10191},
  year    = {2018}
}

@article{bai_deep_2019,
  title   = {Deep equilibrium models},
  author  = {Bai, Shaojie and Kolter, J Zico and Koltun, Vladlen},
  journal = {arXiv preprint arXiv:1909.01377},
  year    = {2019}
}

@inproceedings{amos2017optnet,
  title        = {Optnet: Differentiable optimization as a layer in neural networks},
  author       = {Amos, Brandon and Kolter, J Zico},
  booktitle    = {International Conference on Machine Learning},
  pages        = {136--145},
  year         = {2017},
  organization = {PMLR}
}

@book{kelley1999iterative,
  title     = {Iterative methods for optimization},
  author    = {Kelley, Carl T},
  year      = {1999},
  publisher = {SIAM}
}

@article{luck2016generalized,
  title     = {Generalized method of moments for estimating parameters of stochastic reaction networks},
  author    = {L{\"u}ck, Alexander and Wolf, Verena},
  journal   = {BMC systems biology},
  volume    = {10},
  number    = {1},
  pages     = {1--12},
  year      = {2016},
  publisher = {BioMed Central}
}

@phdthesis{jeisman2006estimation,
  title  = {Estimation of the parameters of stochastic differential equations},
  author = {Jeisman, Joseph Ian},
  year   = {2006},
  school = {Queensland University of Technology}
}

@inproceedings{ghosh2020steer,
  year      = {2020},
  edition   = {},
  number    = {},
  journal   = {},
  pages     = {1-13},
  publisher = {Neural Information Processing Systems Foundation, Inc.},
  school    = {},
  title     = {STEER: simple temporal regularization for neural ODEs},
  volume    = {},
  author    = {Behl, HS and Ghosh, A and Dupont, E and Torr, PHS and Namboodiri, V},
  editor    = {},
  organizer = {34th Conference on Neural Information Processing Systems (NeurIPS)},
  series    = {}
}

@misc{kingma2017adam,
  added-at    = {2020-01-17T03:14:27.000+0100},
  author      = {Kingma, Diederik P. and Ba, Jimmy},
  biburl      = {https://www.bibsonomy.org/bibtex/2d53bcfff0fe1a1d3a4a171352ee6e92c/simon_diener},
  description = {An upgrade over the standard stochastic gradient descend as it is able to apply changes to the learning rate by itself to be able to escape local maxima etc. This methods was used for the dynamic explainable recommender framework by Chen et al.},
  interhash   = {57d2ac873f398f21bb94790081e80394},
  intrahash   = {d53bcfff0fe1a1d3a4a171352ee6e92c},
  keywords    = {final thema:neural_attentional_rating_regression},
  note        = {cite arxiv:1412.6980Comment: Published as a conference paper at the 3rd International Conference  for Learning Representations, San Diego, 2015},
  timestamp   = {2020-01-17T03:14:27.000+0100},
  title       = {Adam: A Method for Stochastic Optimization},
  url         = {http://arxiv.org/abs/1412.6980},
  year        = 2014
}

@article{bettencourt2019taylor,
  title  = {Taylor-Mode Automatic Differentiation for Higher-Order Derivatives in JAX},
  author = {Bettencourt, Jesse and Johnson, Matthew J and Duvenaud, David},
  year   = {2019}
}

@misc{kim2021pderegularized,
  title  = {{\{}PDE{\}}-regularized Neural Networks for Image Classification},
  author = {Jungeun Kim and Seunghyun Hwang and Jihyun Hwang and Kookjin Lee and Dongeun Lee and Noseong Park},
  year   = {2021},
  url    = {https://openreview.net/forum?id=DlPnp5_1JMI}
}

@inproceedings{YAN2020On,
  title     = {On Robustness of Neural Ordinary Differential Equations},
  author    = {Hanshu YAN and Jiawei DU and Vincent TAN and Jiashi FENG},
  booktitle = {International Conference on Learning Representations},
  year      = {2020},
  url       = {https://openreview.net/forum?id=B1e9Y2NYvS}
}

@article{shen2020deep,
  title   = {Deep euler method: solving odes by approximating the local truncation error of the euler method},
  author  = {Shen, Xing and Cheng, Xiaoliang and Liang, Kewei},
  journal = {arXiv preprint arXiv:2003.09573},
  year    = {2020}
}

@article{poli2020hypersolvers,
  title   = {Hypersolvers: Toward fast continuous-depth models},
  author  = {Poli, Michael and Massaroli, Stefano and Yamashita, Atsushi and Asama, Hajime and Park, Jinkyoo},
  journal = {arXiv preprint arXiv:2007.09601},
  year    = {2020}
}

@inproceedings{zhuang2021mali,
  title     = {MALI: A memory efficient and reverse accurate integrator for Neural ODEs},
  author    = {Juntang Zhuang and Nicha C Dvornek and sekhar tatikonda and James s Duncan},
  booktitle = {International Conference on Learning Representations},
  year      = {2021},
  url       = {https://openreview.net/forum?id=blfSjHeFM_e}
}

@misc{kidger2020hey,
  title         = {"Hey, that's not an ODE": Faster ODE Adjoints with 12 Lines of Code},
  author        = {Patrick Kidger and Ricky T. Q. Chen and Terry Lyons},
  year          = {2020},
  eprint        = {2009.09457},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{pal2022mixing,
  title   = {{Continuous Deep Equilibrium Models: Training Neural Odes Faster by Integrating Them to Infinity}},
  author  = {Pal, Avik and Edelman, Alan and Rackauckas, Christopher},
  journal = {arXiv preprint arXiv:2201.12240},
  year    = {2022}
}

@inproceedings{pal2021opening,
  title        = {{Opening the Blackbox: Accelerating Neural Differential Equations by Regularizing Internal Solver Heuristics}},
  author       = {Pal, Avik and Ma, Yingbo and Shah, Viral and Rackauckas, Christopher V},
  booktitle    = {International Conference on Machine Learning},
  pages        = {8325--8335},
  year         = {2021},
  organization = {PMLR}
}

@software{pal2022lux,
  author       = {Pal, Avik},
  title        = {{L}ux: Explicit Parameterization of Deep Neural Networks in Julia},
  year         = {2022},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/avik-pal/Lux.jl/}}
}

@article{anantharaman2020accelerating,
  title   = {Accelerating simulation of stiff nonlinear systems using continuous-time echo state networks},
  author  = {Anantharaman, Ranjan and Ma, Yingbo and Gowda, Shashi and Laughman, Chris and Shah, Viral and Edelman, Alan and Rackauckas, Chris},
  journal = {arXiv preprint arXiv:2010.04004},
  year    = {2020}
}

@article{piche1995stable,
  title     = {An L-stable Rosenbrock method for step-by-step time integration in structural dynamics},
  author    = {Pich{\'e}, Robert},
  journal   = {Computer Methods in Applied Mechanics and Engineering},
  volume    = {126},
  number    = {3-4},
  pages     = {343--354},
  year      = {1995},
  publisher = {Elsevier}
}

@article{robertson1966solution,
  title   = {The solution of a set of reaction rate equations},
  author  = {Robertson, HH},
  journal = {Numerical analysis: an introduction},
  volume  = {178182},
  year    = {1966}
}

 @misc{rackauckas_2022,
  title   = {{Engineering trade-offs in automatic differentiation: From tensorflow and pytorch to jax and julia}},
  url     = {http://www.stochasticlifestyle.com/engineering-trade-offs-in-automatic-differentiation-from-tensorflow-and-pytorch-to-jax-and-julia/},
  journal = {Stochastic Lifestyle},
  author  = {Rackauckas, Christopher},
  year    = {2022},
  month   = {Jan}
} 


@article{bai_multiscale_2020,
  title    = {Multiscale {Deep} {Equilibrium} {Models}},
  url      = {http://arxiv.org/abs/2006.08656},
  language = {en},
  urldate  = {2021-09-14},
  journal  = {arXiv:2006.08656 [cs, stat]},
  author   = {Bai, Shaojie and Koltun, Vladlen and Kolter, J. Zico},
  month    = nov,
  year     = {2020},
  note     = {arXiv: 2006.08656},
  keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
  annote   = {Comment: NeurIPS 2020 Oral},
  file     = {Bai et al. - 2020 - Multiscale Deep Equilibrium Models.pdf:files/248/Bai et al. - 2020 - Multiscale Deep Equilibrium Models.pdf:application/pdf}
}


@incollection{burt1987laplacian,
  title     = {The Laplacian pyramid as a compact image code},
  author    = {Burt, Peter J and Adelson, Edward H},
  booktitle = {Readings in computer vision},
  pages     = {671--679},
  year      = {1987},
  publisher = {Elsevier}
}

@article{farabet2012learning,
  title     = {Learning hierarchical features for scene labeling},
  author    = {Farabet, Clement and Couprie, Camille and Najman, Laurent and LeCun, Yann},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  volume    = {35},
  number    = {8},
  pages     = {1915--1929},
  year      = {2012},
  publisher = {IEEE}
}

@inproceedings{chen2016attention,
  title     = {Attention to scale: Scale-aware semantic image segmentation},
  author    = {Chen, Liang-Chieh and Yang, Yi and Wang, Jiang and Xu, Wei and Yuille, Alan L},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {3640--3649},
  year      = {2016}
}

@article{yu2015multi,
  title   = {Multi-scale context aggregation by dilated convolutions},
  author  = {Yu, Fisher and Koltun, Vladlen},
  journal = {arXiv preprint arXiv:1511.07122},
  year    = {2015}
}

@article{chen2017deeplab,
  title     = {Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs},
  author    = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  volume    = {40},
  number    = {4},
  pages     = {834--848},
  year      = {2017},
  publisher = {IEEE}
}

@article{dupont2019augmented,
  title   = {Augmented neural odes},
  author  = {Dupont, Emilien and Doucet, Arnaud and Teh, Yee Whye},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {32},
  year    = {2019}
}


@misc{djeumou2022taylorlagrange,
  title         = {Taylor-Lagrange Neural Ordinary Differential Equations: Toward Fast Training and Evaluation of Neural ODEs},
  author        = {Franck Djeumou and Cyrus Neary and Eric Goubault and Sylvie Putot and Ufuk Topcu},
  year          = {2022},
  eprint        = {2201.05715},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{xia2021heavy,
  title   = {Heavy Ball Neural Ordinary Differential Equations},
  author  = {Xia, Hedi and Suliafu, Vai and Ji, Hangjie and Nguyen, Tan and Bertozzi, Andrea and Osher, Stanley and Wang, Bao},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {34},
  year    = {2021}
}


@article{lecun1998gradient,
  title     = {Gradient-based learning applied to document recognition},
  author    = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal   = {Proceedings of the IEEE},
  volume    = {86},
  number    = {11},
  pages     = {2278--2324},
  year      = {1998},
  publisher = {Ieee}
}

@inproceedings{citi2012physionet,
  title        = {PhysioNet 2012 Challenge: Predicting mortality of ICU patients using a cascaded SVM-GLM paradigm},
  author       = {Citi, Luca and Barbieri, Riccardo},
  booktitle    = {2012 Computing in Cardiology},
  pages        = {257--260},
  year         = {2012},
  organization = {IEEE}
}

@article{xie_optimization_2021,
  title    = {Optimization {Induced} {Equilibrium} {Networks}},
  url      = {http://arxiv.org/abs/2105.13228},
  abstract = {Implicit equilibrium models, i.e., deep neural networks (DNNs) deﬁned by implicit equations, have been becoming more and more attractive recently. In this paper, we investigate an emerging question: can an implicit equilibrium model’s equilibrium point be regarded as the solution of an optimization problem? To this end, we ﬁrst decompose DNNs into a new class of unit layer that is the proximal operator of an implicit convex function while keeping its output unchanged. Then, the equilibrium model of the unit layer can be derived, named Optimization Induced Equilibrium Networks (OptEq), which can be easily extended to deep layers. The equilibrium point of OptEq can be theoretically connected to the solution of its corresponding convex optimization problem with explicit objectives. Based on this, we can ﬂexibly introduce prior properties to the equilibrium points: 1) modifying the underlying convex problems explicitly so as to change the architectures of OptEq; and 2) merging the information into the ﬁxed point iteration, which guarantees to choose the desired equilibrium point when the ﬁxed point set is non-singleton. We show that deep OptEq outperforms previous implicit models even with fewer parameters. This work establishes the ﬁrst step towards optimization guided design of deep models.},
  language = {en},
  urldate  = {2021-09-14},
  journal  = {arXiv:2105.13228 [cs]},
  author   = {Xie, Xingyu and Wang, Qiuhao and Ling, Zenan and Li, Xia and Wang, Yisen and Liu, Guangcan and Lin, Zhouchen},
  month    = jun,
  year     = {2021},
  note     = {arXiv: 2105.13228},
  keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
  file     = {Xie et al. - 2021 - Optimization Induced Equilibrium Networks.pdf:files/251/Xie et al. - 2021 - Optimization Induced Equilibrium Networks.pdf:application/pdf}
}

@article{ghaoui_implicit_2020,
  title    = {Implicit {Deep} {Learning}},
  url      = {http://arxiv.org/abs/1908.06315},
  abstract = {Implicit deep learning prediction rules generalize the recursive rules of feedforward neural networks. Such rules are based on the solution of a ﬁxed-point equation involving a single vector of hidden features, which is thus only implicitly deﬁned. The implicit framework greatly simpliﬁes the notation of deep learning, and opens up many new possibilities, in terms of novel architectures and algorithms, robustness analysis and design, interpretability, sparsity, and network architecture optimization.},
  language = {en},
  urldate  = {2021-09-14},
  journal  = {arXiv:1908.06315 [cs, math, stat]},
  author   = {Ghaoui, Laurent El and Gu, Fangda and Travacca, Bertrand and Askari, Armin and Tsai, Alicia Y.},
  month    = aug,
  year     = {2020},
  note     = {arXiv: 1908.06315},
  keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Mathematics - Optimization and Control},
  file     = {Ghaoui et al. - 2020 - Implicit Deep Learning.pdf:files/253/Ghaoui et al. - 2020 - Implicit Deep Learning.pdf:application/pdf}
}

@article{revay_lipschitz_2020,
  title    = {Lipschitz {Bounded} {Equilibrium} {Networks}},
  url      = {http://arxiv.org/abs/2010.01732},
  abstract = {This paper introduces new parameterizations of equilibrium neural networks, i.e. networks deﬁned by implicit equations. This model class includes standard multilayer and residual networks as special cases. The new parameterization admits a Lipschitz bound during training via unconstrained optimization: no projections or barrier functions are required. Lipschitz bounds are a common proxy for robustness and appear in many generalization bounds. Furthermore, compared to previous works we show wellposedness (existence of solutions) under less restrictive conditions on the network weights and more natural assumptions on the activation functions: that they are monotone and slope restricted. These results are proved by establishing novel connections with convex optimization, operator splitting on nonEuclidean spaces, and contracting neural ODEs. In image classiﬁcation experiments we show that the Lipschitz bounds are very accurate and improve robustness to adversarial attacks.},
  language = {en},
  urldate  = {2021-09-14},
  journal  = {arXiv:2010.01732 [cs, eess, math, stat]},
  author   = {Revay, Max and Wang, Ruigang and Manchester, Ian R.},
  month    = oct,
  year     = {2020},
  note     = {arXiv: 2010.01732},
  keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Mathematics - Optimization and Control, Electrical Engineering and Systems Science - Systems and Control},
  annote   = {Comment: Conference submission, 19 pages},
  file     = {Revay et al. - 2020 - Lipschitz Bounded Equilibrium Networks.pdf:files/255/Revay et al. - 2020 - Lipschitz Bounded Equilibrium Networks.pdf:application/pdf}
}

@article{johnson2012notes,
  title   = {Notes on adjoint methods for 18.335},
  author  = {Johnson, Steven G},
  journal = {Introduction to Numerical Methods},
  year    = {2006}
}

@article{saad1986gmres,
  title     = {GMRES: A generalized minimal residual algorithm for solving nonsymmetric linear systems},
  author    = {Saad, Youcef and Schultz, Martin H},
  journal   = {SIAM Journal on scientific and statistical computing},
  volume    = {7},
  number    = {3},
  pages     = {856--869},
  year      = {1986},
  publisher = {SIAM}
}

@article{broyden1965class,
  title     = {A class of methods for solving nonlinear simultaneous equations},
  author    = {Broyden, Charles G},
  journal   = {Mathematics of computation},
  volume    = {19},
  number    = {92},
  pages     = {577--593},
  year      = {1965},
  publisher = {JSTOR}
}

@article{bai2021stabilizing,
  title   = {Stabilizing equilibrium models by jacobian regularization},
  author  = {Bai, Shaojie and Koltun, Vladlen and Kolter, J Zico},
  journal = {arXiv preprint arXiv:2106.14342},
  year    = {2021}
}

@article{hutchinson1989stochastic,
  title     = {A stochastic estimator of the trace of the influence matrix for Laplacian smoothing splines},
  author    = {Hutchinson, Michael F},
  journal   = {Communications in Statistics-Simulation and Computation},
  volume    = {18},
  number    = {3},
  pages     = {1059--1076},
  year      = {1989},
  publisher = {Taylor \& Francis}
}

@article{bogacki19893,
  title     = {A 3 (2) pair of Runge-Kutta formulas},
  author    = {Bogacki, Przemyslaw and Shampine, Lawrence F},
  journal   = {Applied Mathematics Letters},
  volume    = {2},
  number    = {4},
  pages     = {321–325},
  year      = {1989},
  publisher = {Elsevier}
}

@article{DifferentialEquations.jl-2017,
  author   = {Rackauckas, Christopher and Nie, Qing},
  doi      = {10.5334/jors.151},
  journal  = {The Journal of Open Research Software},
  keywords = {Applied Mathematics},
  note     = {Exported from https://app.dimensions.ai on 2019/05/05},
  number   = {1},
  pages    = {},
  title    = {DifferentialEquations.jl – A Performant and Feature-Rich Ecosystem for Solving Differential Equations in Julia},
  url      = {https://app.dimensions.ai/details/publication/pub.1085583166 and http://openresearchsoftware.metajnl.com/articles/10.5334/jors.151/galley/245/download/},
  volume   = {5},
  year     = {2017}
}


@article{Flux.jl-2018,
  author        = {Michael Innes and
                   Elliot Saba and
                   Keno Fischer and
                   Dhairya Gandhi and
                   Marco Concetto Rudilosso and
                   Neethu Mariya Joy and
                   Tejan Karmali and
                   Avik Pal and
                   Viral Shah},
  title         = {Fashionable Modelling with Flux},
  journal       = {CoRR},
  volume        = {abs/1811.01457},
  year          = {2018},
  url           = {https://arxiv.org/abs/1811.01457},
  archiveprefix = {arXiv},
  eprint        = {1811.01457},
  timestamp     = {Thu, 22 Nov 2018 17:58:30 +0100},
  biburl        = {https://dblp.org/rec/bib/journals/corr/abs-1811-01457},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{innes:2018,
  author  = {Mike Innes},
  title   = {Flux: Elegant Machine Learning with Julia},
  journal = {Journal of Open Source Software},
  year    = {2018},
  doi     = {10.21105/joss.00602}
}

@article{agrawal2019differentiable,
  title   = {Differentiable convex optimization layers},
  author  = {Agrawal, Akshay and Amos, Brandon and Barratt, Shane and Boyd, Stephen and Diamond, Steven and Kolter, Zico},
  journal = {arXiv preprint arXiv:1910.12430},
  year    = {2019}
}


@inproceedings{lin2017feature,
  title     = {Feature pyramid networks for object detection},
  author    = {Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {2117--2125},
  year      = {2017}
}

@incollection{burt1987laplacian,
  title     = {The Laplacian pyramid as a compact image code},
  author    = {Burt, Peter J and Adelson, Edward H},
  booktitle = {Readings in computer vision},
  pages     = {671--679},
  year      = {1987},
  publisher = {Elsevier}
}

@article{farabet2012learning,
  title     = {Learning hierarchical features for scene labeling},
  author    = {Farabet, Clement and Couprie, Camille and Najman, Laurent and LeCun, Yann},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  volume    = {35},
  number    = {8},
  pages     = {1915--1929},
  year      = {2012},
  publisher = {IEEE}
}

@inproceedings{chen2016attention,
  title     = {Attention to scale: Scale-aware semantic image segmentation},
  author    = {Chen, Liang-Chieh and Yang, Yi and Wang, Jiang and Xu, Wei and Yuille, Alan L},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {3640--3649},
  year      = {2016}
}

@article{yu2015multi,
  title   = {Multi-scale context aggregation by dilated convolutions},
  author  = {Yu, Fisher and Koltun, Vladlen},
  journal = {arXiv preprint arXiv:1511.07122},
  year    = {2015}
}

@article{chen2017deeplab,
  title     = {Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs},
  author    = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  volume    = {40},
  number    = {4},
  pages     = {834--848},
  year      = {2017},
  publisher = {IEEE}
}

@inproceedings{pmlr-v139-pal21a,
  title     = {Opening the Blackbox: Accelerating Neural Differential Equations by Regularizing Internal Solver Heuristics},
  author    = {Pal, Avik and Ma, Yingbo and Shah, Viral and Rackauckas, Christopher V},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  pages     = {8325--8335},
  year      = {2021},
  volume    = {139},
  series    = {Proceedings of Machine Learning Research},
  month     = {18--24 Jul},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v139/pal21a/pal21a.pdf},
  url       = {http://proceedings.mlr.press/v139/pal21a.html}
}

  
@article{kingma2014adam,
  title   = {Adam: A method for stochastic optimization},
  author  = {Kingma, Diederik P and Ba, Jimmy},
  journal = {arXiv preprint arXiv:1412.6980},
  year    = {2014}
}

@article{loshchilov2017decoupled,
  title   = {Decoupled weight decay regularization},
  author  = {Loshchilov, Ilya and Hutter, Frank},
  journal = {arXiv preprint arXiv:1711.05101},
  year    = {2017}
}

@inproceedings{fung2022jfb,
  title     = {JFB: Jacobian-free backpropagation for implicit networks},
  author    = {Fung, Samy Wu and Heaton, Howard and Li, Qiuwei and McKenzie, Daniel and Osher, Stanley and Yin, Wotao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year      = {2022}
}

@article{ghaoui2019implicit,
  title   = {Implicit deep learning},
  author  = {Ghaoui, Laurent El and Gu, Fangda and Travacca, Bertrand and Askari, Armin and Tsai, Alicia Y},
  journal = {arXiv preprint arXiv:1908.06315},
  year    = {2019}
}

@misc{djeumou2022taylorlagrange,
  title         = {Taylor-Lagrange Neural Ordinary Differential Equations: Toward Fast Training and Evaluation of Neural ODEs},
  author        = {Franck Djeumou and Cyrus Neary and Eric Goubault and Sylvie Putot and Ufuk Topcu},
  year          = {2022},
  eprint        = {2201.05715},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{xia2021heavy,
  title   = {Heavy Ball Neural Ordinary Differential Equations},
  author  = {Xia, Hedi and Suliafu, Vai and Ji, Hangjie and Nguyen, Tan and Bertozzi, Andrea and Osher, Stanley and Wang, Bao},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {34},
  year    = {2021}
}

@book{bulsari1995neural,
  title     = {Neural Networks for Chemical Engineers},
  author    = {Bulsari, A.B.},
  isbn      = {9780444820976},
  lccn      = {95009927},
  series    = {Computer-aided chemical engineering},
  url       = {https://books.google.com/books?id=atBTAAAAMAAJ},
  year      = {1995},
  publisher = {Elsevier}
}

@article{rico1992discrete,
  title     = {Discrete-vs. continuous-time nonlinear signal processing of Cu electrodissolution data},
  author    = {Rico-Martinez, R and Krischer, K and Kevrekidis, IG and Kube, MC and Hudson, JL},
  journal   = {Chemical Engineering Communications},
  volume    = {118},
  number    = {1},
  pages     = {25--48},
  year      = {1992},
  publisher = {Taylor \& Francis}
}

@article{netzer2011reading,
  title  = {Reading digits in natural images with unsupervised feature learning},
  author = {Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  year   = {2011}
}

@article{krizhevsky2009learning,
  title     = {Learning multiple layers of features from tiny images},
  author    = {Krizhevsky, Alex and Hinton, Geoffrey and others},
  year      = {2009},
  publisher = {Citeseer}
}

@article{kawaguchi2021theory,
  title   = {On the Theory of Implicit Deep Learning: Global Convergence with Implicit Layers},
  author  = {Kawaguchi, Kenji},
  journal = {arXiv preprint arXiv:2102.07346},
  year    = {2021}
}

@article{rackauckas2018comparison,
  title   = {A comparison of automatic differentiation and continuous sensitivity analysis for derivatives of differential equation solutions},
  author  = {Rackauckas, Christopher and Ma, Yingbo and Dixit, Vaibhav and Guo, Xingjian and Innes, Mike and Revels, Jarrett and Nyberg, Joakim and Ivaturi, Vijay},
  journal = {arXiv preprint arXiv:1812.01892},
  year    = {2018}
}
u
@inproceedings{deng2009imagenet,
  title        = {Imagenet: A large-scale hierarchical image database},
  author       = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle    = {2009 IEEE conference on computer vision and pattern recognition},
  pages        = {248--255},
  year         = {2009},
  organization = {Ieee}
}

@inproceedings{bai2021neural,
  title     = {Neural deep equilibrium solvers},
  author    = {Bai, Shaojie and Koltun, Vladlen and Kolter, J Zico},
  booktitle = {International Conference on Learning Representations},
  year      = {2021}
}

@article{pal2023locally,
  title   = {{Locally Regularized Neural Differential Equations: Some Black Boxes Were Meant to Remain Closed!}},
  author  = {Pal, Avik and Edelman, Alan and Rackauckas, Chris},
  journal = {arXiv preprint arXiv:2303.02262},
  year    = {2023}
}

@article{sherman1950adjustment,
  title     = {Adjustment of an inverse matrix corresponding to a change in one element of a given matrix},
  author    = {Sherman, Jack and Morrison, Winifred J},
  journal   = {The Annals of Mathematical Statistics},
  volume    = {21},
  number    = {1},
  pages     = {124--127},
  year      = {1950},
  publisher = {JSTOR}
}

@article{anderson1965iterative,
  title     = {Iterative procedures for nonlinear integral equations},
  author    = {Anderson, Donald G},
  journal   = {Journal of the ACM (JACM)},
  volume    = {12},
  number    = {4},
  pages     = {547--560},
  year      = {1965},
  publisher = {ACM New York, NY, USA}
}

@article{hindmarsh2005sundials,
  author     = {Hindmarsh, Alan C. and Brown, Peter N. and Grant, Keith E. and Lee, Steven L. and Serban, Radu and Shumaker, Dan E. and Woodward, Carol S.},
  title      = {SUNDIALS: Suite of Nonlinear and Differential/Algebraic Equation Solvers},
  year       = {2005},
  issue_date = {September 2005},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {31},
  number     = {3},
  issn       = {0098-3500},
  url        = {https://doi.org/10.1145/1089014.1089020},
  doi        = {10.1145/1089014.1089020},
  abstract   = {SUNDIALS is a suite of advanced computational codes for solving large-scale problems that can be modeled as a system of nonlinear algebraic equations, or as initial-value problems in ordinary differential or differential-algebraic equations. The basic versions of these codes are called KINSOL, CVODE, and IDA, respectively. The codes are written in ANSI standard C and are suitable for either serial or parallel machine environments. Common and notable features of these codes include inexact Newton-Krylov methods for solving large-scale nonlinear systems; linear multistep methods for time-dependent problems; a highly modular structure to allow incorporation of different preconditioning and/or linear solver methods; and clear interfaces allowing for users to provide their own data structures underneath the solvers. We describe the current capabilities of the codes, along with some of the algorithms and heuristics used to achieve efficiency and robustness. We also describe how the codes stem from previous and widely used Fortran 77 solvers, and how the codes have been augmented with forward and adjoint methods for carrying out first-order sensitivity analysis with respect to model parameters or initial conditions.},
  journal    = {ACM Trans. Math. Softw.},
  month      = {sep},
  pages      = {363–396},
  numpages   = {34},
  keywords   = {DAEs, nonlinear systems, ODEs, sensitivity analysis}
}